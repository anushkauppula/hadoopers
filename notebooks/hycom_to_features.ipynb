{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cc0d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_PATH: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\raw\n",
      "PROC_PATH: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\processed\n",
      "Total rivers: 1387\n",
      "\n",
      "Analyzing river coordinate ranges:\n",
      "Min/Max mouth_lat: -6699114.72, 13241189.53\n",
      "Min/Max mouth_lon: -18310017.91, 19761475.71\n",
      "\n",
      "After scaling by 100,000:\n",
      "    river_name  mouth_lat_deg  mouth_lon_deg\n",
      "0       Rungwa      -8.038435      35.622237\n",
      "1      Ligonha     -17.036085      41.608649\n",
      "2       Dongwe     -15.596923      26.644385\n",
      "3        Cuito     -14.198700      20.414734\n",
      "4        Bagoé      12.960210      -7.303820\n",
      "5      Hadejia      12.849537       8.341243\n",
      "6         Sous      35.505781      -9.517816\n",
      "7  Oum Er Rbia      38.288080      -6.679169\n",
      "8   San Miguel     -14.993571     -71.244474\n",
      "9        Coari      -4.465621     -70.328643\n",
      "\n",
      "Lat range: -66.99 to 132.41\n",
      "Lon range: -183.10 to 197.61\n",
      "\n",
      "Rivers after cleaning: 1387\n",
      "\n",
      "Found 6 HYCOM files:\n",
      "  uv3z_08-31-2024.nc4\n",
      "  uv3z_09-01-2024.nc4\n",
      "  uv3z_09-02-2024.nc4\n",
      "  uv3z_09-03-2024.nc4\n",
      "  uv3z_09-04-2024.nc4\n",
      "  uv3z_09-05-2024.nc4\n",
      "\n",
      "Examining first file: uv3z_08-31-2024.nc4\n",
      "Dataset variables: ['water_u_bottom', 'water_v_bottom']\n",
      "Dataset coordinates: ['time', 'lat', 'lon']\n",
      "Dataset dimensions: {'time': 1, 'lat': 4251, 'lon': 4500}\n",
      "\n",
      "HYCOM region bounds:\n",
      "  Latitude: -80.0° to 90.0°\n",
      "  Longitude: 0.0° to 359.9°\n",
      "\n",
      "Time in first file: ['2024-08-31T09:00:00.000000000']\n",
      "\n",
      "Rivers within HYCOM region: 1387\n",
      "\n",
      "Sample rivers to process:\n",
      "    river_name                      country  mouth_lat_deg  mouth_lon_deg  \\\n",
      "0       Rungwa  United Republic of Tanzania      -8.038435      35.622237   \n",
      "1      Ligonha                   Mozambique     -17.036085      41.608649   \n",
      "2       Dongwe                       Zambia     -15.596923      26.644385   \n",
      "3        Cuito                       Angola     -14.198700      20.414734   \n",
      "4        Bagoé                         Mali      12.960210      -7.303820   \n",
      "5      Hadejia                      Nigeria      12.849537       8.341243   \n",
      "6         Sous                      Morocco      35.505781      -9.517816   \n",
      "7  Oum Er Rbia                      Morocco      38.288080      -6.679169   \n",
      "8   San Miguel                      Bolivia     -14.993571     -71.244474   \n",
      "9        Coari                       Brazil      -4.465621     -70.328643   \n",
      "\n",
      "   lon_adjusted  \n",
      "0     35.622237  \n",
      "1     41.608649  \n",
      "2     26.644385  \n",
      "3     20.414734  \n",
      "4    352.696180  \n",
      "5      8.341243  \n",
      "6    350.482184  \n",
      "7    353.320831  \n",
      "8    288.755526  \n",
      "9    289.671357  \n",
      "\n",
      "============================================================\n",
      "Processing file 1/6: uv3z_08-31-2024.nc4\n",
      "============================================================\n",
      "File date: 2024-08-31\n",
      "Data time: ['2024-08-31T09:00:00.000000000']\n",
      "Using bottom velocity variables: water_u_bottom, water_v_bottom\n",
      "  Valid currents: 653/1387 rivers\n",
      "  Mean speed: 0.0294 m/s\n",
      "  Max speed: 0.2232 m/s\n",
      "  Top rivers today:\n",
      "    Saint Lawrence: 0.2232 m/s\n",
      "    Punguè: 0.2220 m/s\n",
      "    Gan: 0.2203 m/s\n",
      "    Gan: 0.2203 m/s\n",
      "    Mogami: 0.2193 m/s\n",
      "\n",
      "============================================================\n",
      "Processing file 2/6: uv3z_09-01-2024.nc4\n",
      "============================================================\n",
      "File date: 2024-09-01\n",
      "Data time: ['2024-09-01T09:00:00.000000000']\n",
      "Using bottom velocity variables: water_u_bottom, water_v_bottom\n",
      "  Valid currents: 653/1387 rivers\n",
      "  Mean speed: 0.0324 m/s\n",
      "  Max speed: 0.3024 m/s\n",
      "  Top rivers today:\n",
      "    Ticino: 0.3024 m/s\n",
      "    Gan: 0.2390 m/s\n",
      "    Gan: 0.2390 m/s\n",
      "    Saint Lawrence: 0.2274 m/s\n",
      "    Yong: 0.2269 m/s\n",
      "\n",
      "============================================================\n",
      "Processing file 3/6: uv3z_09-02-2024.nc4\n",
      "============================================================\n",
      "File date: 2024-09-02\n",
      "Data time: ['2024-09-02T09:00:00.000000000']\n",
      "Using bottom velocity variables: water_u_bottom, water_v_bottom\n",
      "  Valid currents: 653/1387 rivers\n",
      "  Mean speed: 0.0308 m/s\n",
      "  Max speed: 0.3410 m/s\n",
      "  Top rivers today:\n",
      "    Ticino: 0.3410 m/s\n",
      "    Yong: 0.2613 m/s\n",
      "    Yu: 0.2613 m/s\n",
      "    Gan: 0.2463 m/s\n",
      "    Gan: 0.2463 m/s\n",
      "\n",
      "============================================================\n",
      "Processing file 4/6: uv3z_09-03-2024.nc4\n",
      "============================================================\n",
      "File date: 2024-09-03\n",
      "Data time: ['2024-09-03T09:00:00.000000000']\n",
      "Using bottom velocity variables: water_u_bottom, water_v_bottom\n",
      "  Valid currents: 653/1387 rivers\n",
      "  Mean speed: 0.0287 m/s\n",
      "  Max speed: 0.2397 m/s\n",
      "  Top rivers today:\n",
      "    Gan: 0.2397 m/s\n",
      "    Gan: 0.2397 m/s\n",
      "    Yong: 0.2191 m/s\n",
      "    Yu: 0.2191 m/s\n",
      "    Orange: 0.2130 m/s\n",
      "\n",
      "============================================================\n",
      "Processing file 5/6: uv3z_09-04-2024.nc4\n",
      "============================================================\n",
      "File date: 2024-09-04\n",
      "Data time: ['2024-09-04T09:00:00.000000000']\n",
      "Using bottom velocity variables: water_u_bottom, water_v_bottom\n",
      "  Valid currents: 653/1387 rivers\n",
      "  Mean speed: 0.0286 m/s\n",
      "  Max speed: 0.2562 m/s\n",
      "  Top rivers today:\n",
      "    Orange: 0.2562 m/s\n",
      "    Gan: 0.2223 m/s\n",
      "    Gan: 0.2223 m/s\n",
      "    Yong: 0.2142 m/s\n",
      "    Yu: 0.2142 m/s\n",
      "\n",
      "============================================================\n",
      "Processing file 6/6: uv3z_09-05-2024.nc4\n",
      "============================================================\n",
      "File date: 2024-09-05\n",
      "Data time: ['2024-09-05T09:00:00.000000000']\n",
      "Using bottom velocity variables: water_u_bottom, water_v_bottom\n",
      "  Valid currents: 653/1387 rivers\n",
      "  Mean speed: 0.0310 m/s\n",
      "  Max speed: 0.3303 m/s\n",
      "  Top rivers today:\n",
      "    Lancang: 0.3303 m/s\n",
      "    Ngun: 0.2991 m/s\n",
      "    Gamtoos: 0.2732 m/s\n",
      "    Orange: 0.2652 m/s\n",
      "    Ngun: 0.2569 m/s\n",
      "\n",
      "============================================================\n",
      "COMBINED RESULTS SUMMARY\n",
      "============================================================\n",
      "Total measurements: 8322\n",
      "Unique rivers: 1082\n",
      "Unique dates: 6\n",
      "\n",
      "Rivers with valid data: 523\n",
      "\n",
      "Top 10 rivers by average current speed:\n",
      "                     country  avg_speed_ms  max_speed_ms  n_days\n",
      "river_name                                                      \n",
      "Gan                    China        0.2306        0.2463      12\n",
      "Yong                   China        0.2136        0.2613       6\n",
      "Yu                     China        0.2136        0.2613       6\n",
      "Mogami                 Japan        0.1982        0.2193       6\n",
      "Punguè            Mozambique        0.1734        0.2249       6\n",
      "Gamtoos         South Africa        0.1614        0.2732       6\n",
      "Hong                   China        0.1600        0.2235       6\n",
      "Saint Lawrence        Canada        0.1553        0.2420       6\n",
      "Caledon         South Africa        0.1484        0.2009       6\n",
      "Hongshui               China        0.1438        0.1892       6\n",
      "\n",
      "Overall statistics:\n",
      "  Mean current speed: 0.0309 ± 0.0366 m/s\n",
      "  Maximum average speed: 0.2306 m/s\n",
      "  Minimum average speed: 0.0000 m/s\n",
      "\n",
      "Saved detailed results to: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\processed\\river_currents_detailed_2024.csv\n",
      "Saved river summary to: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\processed\\river_currents_summary_2024.csv\n",
      "Saved simple results to: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\processed\\river_currents_simple_2024.csv\n",
      "\n",
      "Saved analysis report to: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\processed\\currents_analysis_report.txt\n",
      "Saved time series plot to: C:\\Users\\s572269\\Downloads\\river_plastic_predictor\\data\\processed\\currents_time_series.png\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------- paths ----------\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\s572269\\Downloads\\river_plastic_predictor\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_PATH = DATA_DIR / \"raw\"\n",
    "PROC_PATH = DATA_DIR / \"processed\"\n",
    "PROC_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"RAW_PATH:\", RAW_PATH)\n",
    "print(\"PROC_PATH:\", PROC_PATH)\n",
    "\n",
    "# ---------- load rivers ----------\n",
    "rivers = pd.read_csv(RAW_PATH / \"global_rivers_dataset.csv\")\n",
    "print(f\"Total rivers: {len(rivers)}\")\n",
    "\n",
    "# Fix river coordinates - they appear to be in some projection, not degrees\n",
    "# Let's try a different approach: normalize and approximate\n",
    "print(\"\\nAnalyzing river coordinate ranges:\")\n",
    "print(f\"Min/Max mouth_lat: {rivers['mouth_lat'].min():.2f}, {rivers['mouth_lat'].max():.2f}\")\n",
    "print(f\"Min/Max mouth_lon: {rivers['mouth_lon'].min():.2f}, {rivers['mouth_lon'].max():.2f}\")\n",
    "\n",
    "# Based on the previous analysis, let's try scaling by 1e5 instead\n",
    "# This gives more reasonable degree values\n",
    "rivers[\"mouth_lat_deg\"] = rivers[\"mouth_lat\"] / 1e5\n",
    "rivers[\"mouth_lon_deg\"] = rivers[\"mouth_lon\"] / 1e5\n",
    "\n",
    "print(\"\\nAfter scaling by 100,000:\")\n",
    "print(rivers[['river_name', 'mouth_lat_deg', 'mouth_lon_deg']].head(10))\n",
    "print(f\"\\nLat range: {rivers['mouth_lat_deg'].min():.2f} to {rivers['mouth_lat_deg'].max():.2f}\")\n",
    "print(f\"Lon range: {rivers['mouth_lon_deg'].min():.2f} to {rivers['mouth_lon_deg'].max():.2f}\")\n",
    "\n",
    "# Clean up extreme values\n",
    "rivers.loc[rivers['mouth_lat_deg'] > 90, 'mouth_lat_deg'] = 90\n",
    "rivers.loc[rivers['mouth_lat_deg'] < -90, 'mouth_lat_deg'] = -90\n",
    "rivers.loc[rivers['mouth_lon_deg'] > 180, 'mouth_lon_deg'] = 180\n",
    "rivers.loc[rivers['mouth_lon_deg'] < -180, 'mouth_lon_deg'] = -180\n",
    "\n",
    "# Create filtered dataset\n",
    "rivers_small = rivers[[\"river_name\", \"main_country\", \"mouth_lat_deg\", \"mouth_lon_deg\"]].copy()\n",
    "rivers_small = rivers_small.rename(columns={\"main_country\": \"country\"}).dropna()\n",
    "\n",
    "print(f\"\\nRivers after cleaning: {len(rivers_small)}\")\n",
    "\n",
    "# ---------- Find all HYCOM files ----------\n",
    "# Find all files starting with uv3z_ in the raw directory\n",
    "hycom_files = sorted(list(RAW_PATH.glob(\"uv3z_*.nc4\")))\n",
    "print(f\"\\nFound {len(hycom_files)} HYCOM files:\")\n",
    "for f in hycom_files:\n",
    "    print(f\"  {f.name}\")\n",
    "\n",
    "if len(hycom_files) == 0:\n",
    "    raise FileNotFoundError(\"No HYCOM files found! Expected files like uv3z_08-31-2024.nc4\")\n",
    "\n",
    "# ---------- Check first file to understand structure ----------\n",
    "first_file = hycom_files[0]\n",
    "print(f\"\\nExamining first file: {first_file.name}\")\n",
    "ds_sample = xr.open_dataset(first_file)\n",
    "\n",
    "print(\"Dataset variables:\", list(ds_sample.data_vars))\n",
    "print(\"Dataset coordinates:\", list(ds_sample.coords))\n",
    "print(\"Dataset dimensions:\", dict(ds_sample.dims))\n",
    "\n",
    "# Get HYCOM bounds from first file\n",
    "hycom_lat_min = float(ds_sample.lat.min())\n",
    "hycom_lat_max = float(ds_sample.lat.max())\n",
    "hycom_lon_min = float(ds_sample.lon.min())\n",
    "hycom_lon_max = float(ds_sample.lon.max())\n",
    "\n",
    "print(f\"\\nHYCOM region bounds:\")\n",
    "print(f\"  Latitude: {hycom_lat_min:.1f}° to {hycom_lat_max:.1f}°\")\n",
    "print(f\"  Longitude: {hycom_lon_min:.1f}° to {hycom_lon_max:.1f}°\")\n",
    "\n",
    "# Check what time periods are covered\n",
    "print(f\"\\nTime in first file: {ds_sample.time.values}\")\n",
    "ds_sample.close()\n",
    "\n",
    "# ---------- Filter rivers in HYCOM region ----------\n",
    "# Adjust longitudes to match HYCOM's 0-360 system if needed\n",
    "def adjust_lon_for_hycom(lon):\n",
    "    \"\"\"Adjust longitude to match HYCOM coordinate system\"\"\"\n",
    "    # HYCOM seems to use 0-360, but check from data\n",
    "    if hycom_lon_min >= 0 and hycom_lon_max <= 360 and lon < 0:\n",
    "        return lon + 360\n",
    "    return lon\n",
    "\n",
    "rivers_small[\"lon_adjusted\"] = rivers_small[\"mouth_lon_deg\"].apply(adjust_lon_for_hycom)\n",
    "\n",
    "# Find rivers within HYCOM region\n",
    "in_region_mask = (\n",
    "    (rivers_small[\"mouth_lat_deg\"] >= hycom_lat_min) &\n",
    "    (rivers_small[\"mouth_lat_deg\"] <= hycom_lat_max) &\n",
    "    (rivers_small[\"lon_adjusted\"] >= hycom_lon_min) &\n",
    "    (rivers_small[\"lon_adjusted\"] <= hycom_lon_max)\n",
    ")\n",
    "\n",
    "rivers_in_region = rivers_small[in_region_mask].copy()\n",
    "print(f\"\\nRivers within HYCOM region: {len(rivers_in_region)}\")\n",
    "\n",
    "if len(rivers_in_region) == 0:\n",
    "    print(\"No rivers found in HYCOM region. Finding nearest rivers...\")\n",
    "    \n",
    "    # Calculate simple distance to region center\n",
    "    region_center_lat = (hycom_lat_min + hycom_lat_max) / 2\n",
    "    region_center_lon = (hycom_lon_min + hycom_lon_max) / 2\n",
    "    \n",
    "    rivers_small['dist_to_region'] = np.sqrt(\n",
    "        (rivers_small['mouth_lat_deg'] - region_center_lat)**2 +\n",
    "        ((rivers_small['lon_adjusted'] - region_center_lon) * np.cos(np.radians(region_center_lat)))**2\n",
    "    )\n",
    "    \n",
    "    # Take closest 100 rivers\n",
    "    rivers_in_region = rivers_small.nsmallest(100, 'dist_to_region')\n",
    "    print(f\"Selected {len(rivers_in_region)} closest rivers\")\n",
    "\n",
    "print(\"\\nSample rivers to process:\")\n",
    "print(rivers_in_region[['river_name', 'country', 'mouth_lat_deg', 'mouth_lon_deg', 'lon_adjusted']].head(10))\n",
    "\n",
    "# ---------- Process all HYCOM files ----------\n",
    "all_results = []\n",
    "\n",
    "for file_idx, hycom_file in enumerate(hycom_files):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing file {file_idx+1}/{len(hycom_files)}: {hycom_file.name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Open the current file\n",
    "    ds = xr.open_dataset(hycom_file)\n",
    "    \n",
    "    # Parse date from filename\n",
    "    date_str = hycom_file.stem.replace(\"uv3z_\", \"\")\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%m-%d-%Y\").date()\n",
    "    except:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\").date() if len(date_str) == 8 else None\n",
    "    \n",
    "    print(f\"File date: {file_date}\")\n",
    "    print(f\"Data time: {ds.time.values}\")\n",
    "    \n",
    "    # Use bottom velocities if available, otherwise surface\n",
    "    if \"water_u_bottom\" in ds.data_vars and \"water_v_bottom\" in ds.data_vars:\n",
    "        u_name, v_name = \"water_u_bottom\", \"water_v_bottom\"\n",
    "        depth_type = \"bottom\"\n",
    "    else:\n",
    "        u_name, v_name = \"water_u\", \"water_v\"\n",
    "        depth_type = \"surface\"\n",
    "    \n",
    "    print(f\"Using {depth_type} velocity variables: {u_name}, {v_name}\")\n",
    "    \n",
    "    # Apply scaling factors if they exist\n",
    "    for var_name in [u_name, v_name]:\n",
    "        var = ds[var_name]\n",
    "        if 'scale_factor' in var.attrs:\n",
    "            scale = var.attrs['scale_factor']\n",
    "            offset = var.attrs.get('add_offset', 0.0)\n",
    "            fill_value = var.attrs.get('_FillValue', np.nan)\n",
    "            \n",
    "            # Apply scaling\n",
    "            if not np.isnan(fill_value):\n",
    "                mask = var == fill_value\n",
    "                ds[var_name] = var.where(~mask) * scale + offset\n",
    "                ds[var_name] = ds[var_name].where(ds[var_name] != fill_value)\n",
    "            else:\n",
    "                ds[var_name] = var * scale + offset\n",
    "    \n",
    "    # Select first time step if multiple\n",
    "    if \"time\" in ds.dims and len(ds.time) > 1:\n",
    "        ds_single = ds.isel(time=0)\n",
    "    else:\n",
    "        ds_single = ds\n",
    "    \n",
    "    # Process each river\n",
    "    daily_results = []\n",
    "    \n",
    "    for idx, river_row in rivers_in_region.iterrows():\n",
    "        lat = river_row[\"mouth_lat_deg\"]\n",
    "        lon = river_row[\"lon_adjusted\"]\n",
    "        \n",
    "        # Clamp to HYCOM bounds\n",
    "        lat_clamped = np.clip(lat, hycom_lat_min, hycom_lat_max)\n",
    "        lon_clamped = np.clip(lon, hycom_lon_min, hycom_lon_max)\n",
    "        \n",
    "        try:\n",
    "            # Try nearest neighbor interpolation\n",
    "            pt = ds_single.sel(\n",
    "                lat=lat_clamped,\n",
    "                lon=lon_clamped,\n",
    "                method='nearest'\n",
    "            )\n",
    "            \n",
    "            u = float(pt[u_name].values)\n",
    "            v = float(pt[v_name].values)\n",
    "            \n",
    "            # If nearest gives NaN, try linear\n",
    "            if np.isnan(u) or np.isnan(v):\n",
    "                pt = ds_single.interp(\n",
    "                    lat=lat_clamped,\n",
    "                    lon=lon_clamped,\n",
    "                    method='linear'\n",
    "                )\n",
    "                u = float(pt[u_name].values)\n",
    "                v = float(pt[v_name].values)\n",
    "            \n",
    "            if np.isnan(u) or np.isnan(v):\n",
    "                current_speed = np.nan\n",
    "            else:\n",
    "                current_speed = np.sqrt(u**2 + v**2)\n",
    "            \n",
    "            # Check if point was clamped\n",
    "            was_clamped = (lat != lat_clamped) or (lon != lon_clamped)\n",
    "            \n",
    "        except Exception as e:\n",
    "            u, v, current_speed = np.nan, np.nan, np.nan\n",
    "            was_clamped = True\n",
    "        \n",
    "        result = {\n",
    "            'river_name': river_row['river_name'],\n",
    "            'country': river_row['country'],\n",
    "            'original_lat': river_row['mouth_lat_deg'],\n",
    "            'original_lon': river_row['mouth_lon_deg'],\n",
    "            'adjusted_lon': river_row['lon_adjusted'],\n",
    "            'used_lat': lat_clamped,\n",
    "            'used_lon': lon_clamped,\n",
    "            'date': file_date,\n",
    "            'u_ms': u,\n",
    "            'v_ms': v,\n",
    "            'current_speed_ms': current_speed,\n",
    "            'was_clamped': was_clamped,\n",
    "            'file_source': hycom_file.name,\n",
    "            'depth_type': depth_type\n",
    "        }\n",
    "        \n",
    "        daily_results.append(result)\n",
    "    \n",
    "    # Convert daily results to DataFrame\n",
    "    daily_df = pd.DataFrame(daily_results)\n",
    "    \n",
    "    # Calculate statistics for this day\n",
    "    valid_speeds = daily_df['current_speed_ms'].dropna()\n",
    "    if len(valid_speeds) > 0:\n",
    "        print(f\"  Valid currents: {len(valid_speeds)}/{len(daily_df)} rivers\")\n",
    "        print(f\"  Mean speed: {valid_speeds.mean():.4f} m/s\")\n",
    "        print(f\"  Max speed: {valid_speeds.max():.4f} m/s\")\n",
    "        \n",
    "        # Show top rivers for this day\n",
    "        top_rivers = daily_df.nlargest(5, 'current_speed_ms')\n",
    "        print(\"  Top rivers today:\")\n",
    "        for _, row in top_rivers.iterrows():\n",
    "            print(f\"    {row['river_name']}: {row['current_speed_ms']:.4f} m/s\")\n",
    "    else:\n",
    "        print(f\"  No valid current data found for this day\")\n",
    "    \n",
    "    all_results.append(daily_df)\n",
    "    \n",
    "    # Close dataset\n",
    "    ds.close()\n",
    "\n",
    "# ---------- Combine all results ----------\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMBINED RESULTS SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total measurements: {len(combined_results)}\")\n",
    "    print(f\"Unique rivers: {combined_results['river_name'].nunique()}\")\n",
    "    print(f\"Unique dates: {combined_results['date'].nunique()}\")\n",
    "    \n",
    "    # Calculate river-wise statistics\n",
    "    river_stats = combined_results.groupby('river_name').agg({\n",
    "        'current_speed_ms': ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'country': 'first',\n",
    "        'original_lat': 'first',\n",
    "        'original_lon': 'first'\n",
    "    }).round(4)\n",
    "    \n",
    "    river_stats.columns = ['_'.join(col).strip() for col in river_stats.columns.values]\n",
    "    river_stats = river_stats.rename(columns={\n",
    "        'current_speed_ms_count': 'n_days',\n",
    "        'current_speed_ms_mean': 'avg_speed_ms',\n",
    "        'current_speed_ms_std': 'std_speed_ms',\n",
    "        'current_speed_ms_min': 'min_speed_ms',\n",
    "        'current_speed_ms_max': 'max_speed_ms',\n",
    "        'country_first': 'country',\n",
    "        'original_lat_first': 'latitude',\n",
    "        'original_lon_first': 'longitude'\n",
    "    })\n",
    "    \n",
    "    # Filter rivers with at least some valid data\n",
    "    rivers_with_data = river_stats[river_stats['n_days'] > 0].copy()\n",
    "    print(f\"\\nRivers with valid data: {len(rivers_with_data)}\")\n",
    "    \n",
    "    if len(rivers_with_data) > 0:\n",
    "        print(\"\\nTop 10 rivers by average current speed:\")\n",
    "        top_rivers = rivers_with_data.nlargest(10, 'avg_speed_ms')\n",
    "        print(top_rivers[['country', 'avg_speed_ms', 'max_speed_ms', 'n_days']])\n",
    "        \n",
    "        print(f\"\\nOverall statistics:\")\n",
    "        print(f\"  Mean current speed: {rivers_with_data['avg_speed_ms'].mean():.4f} ± {rivers_with_data['avg_speed_ms'].std():.4f} m/s\")\n",
    "        print(f\"  Maximum average speed: {rivers_with_data['avg_speed_ms'].max():.4f} m/s\")\n",
    "        print(f\"  Minimum average speed: {rivers_with_data['avg_speed_ms'].min():.4f} m/s\")\n",
    "        \n",
    "        # ---------- Save results ----------\n",
    "        # Save detailed results\n",
    "        detailed_path = PROC_PATH / \"river_currents_detailed_2024.csv\"\n",
    "        combined_results.to_csv(detailed_path, index=False)\n",
    "        print(f\"\\nSaved detailed results to: {detailed_path}\")\n",
    "        \n",
    "        # Save river summary\n",
    "        summary_path = PROC_PATH / \"river_currents_summary_2024.csv\"\n",
    "        rivers_with_data.to_csv(summary_path)\n",
    "        print(f\"Saved river summary to: {summary_path}\")\n",
    "        \n",
    "        # Save a simple version with just the essentials\n",
    "        simple_results = combined_results[['river_name', 'country', 'date', 'current_speed_ms', 'u_ms', 'v_ms']].copy()\n",
    "        simple_path = PROC_PATH / \"river_currents_simple_2024.csv\"\n",
    "        simple_results.to_csv(simple_path, index=False)\n",
    "        print(f\"Saved simple results to: {simple_path}\")\n",
    "        \n",
    "        # ---------- Create summary report ----------\n",
    "        report_path = PROC_PATH / \"currents_analysis_report.txt\"\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"River Currents Analysis Report\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "            f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"HYCOM Files Processed: {len(hycom_files)}\\n\")\n",
    "            f.write(f\"Files: {', '.join([f.name for f in hycom_files])}\\n\\n\")\n",
    "            f.write(f\"HYCOM Region: Lat [{hycom_lat_min:.1f}°, {hycom_lat_max:.1f}°], \"\n",
    "                   f\"Lon [{hycom_lon_min:.1f}°, {hycom_lon_max:.1f}°]\\n\")\n",
    "            f.write(f\"Rivers Analyzed: {len(rivers_in_region)}\\n\")\n",
    "            f.write(f\"Rivers with Valid Data: {len(rivers_with_data)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Overall Statistics:\\n\")\n",
    "            f.write(f\"  Mean Current Speed: {rivers_with_data['avg_speed_ms'].mean():.4f} m/s\\n\")\n",
    "            f.write(f\"  Std Dev: {rivers_with_data['avg_speed_ms'].std():.4f} m/s\\n\")\n",
    "            f.write(f\"  Range: {rivers_with_data['avg_speed_ms'].min():.4f} to {rivers_with_data['avg_speed_ms'].max():.4f} m/s\\n\\n\")\n",
    "            \n",
    "            f.write(\"Top 10 Rivers by Current Speed:\\n\")\n",
    "            for idx, (river_name, row) in enumerate(top_rivers.iterrows(), 1):\n",
    "                f.write(f\"{idx:2d}. {river_name:30s} {row['country']:20s} \"\n",
    "                       f\"Avg: {row['avg_speed_ms']:.4f} m/s  Max: {row['max_speed_ms']:.4f} m/s  \"\n",
    "                       f\"Days: {row['n_days']}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nFiles Generated:\\n\")\n",
    "            f.write(f\"  1. {detailed_path.name} - Detailed daily measurements\\n\")\n",
    "            f.write(f\"  2. {summary_path.name} - River-wise statistics\\n\")\n",
    "            f.write(f\"  3. {simple_path.name} - Simplified daily data\\n\")\n",
    "            f.write(f\"  4. {report_path.name} - This report\\n\")\n",
    "        \n",
    "        print(f\"\\nSaved analysis report to: {report_path}\")\n",
    "        \n",
    "        # ---------- Create visualization ----------\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            # Create time series plot for top rivers\n",
    "            top_river_names = top_rivers.index.tolist()[:5]\n",
    "            \n",
    "            plt.figure(figsize=(14, 8))\n",
    "            \n",
    "            for river_name in top_river_names:\n",
    "                river_data = combined_results[combined_results['river_name'] == river_name]\n",
    "                river_data = river_data.sort_values('date')\n",
    "                \n",
    "                plt.plot(river_data['date'], river_data['current_speed_ms'], \n",
    "                        marker='o', linewidth=2, markersize=5, label=river_name)\n",
    "            \n",
    "            plt.title('Daily Current Speeds for Top Rivers (August-September 2024)', fontsize=14)\n",
    "            plt.xlabel('Date', fontsize=12)\n",
    "            plt.ylabel('Current Speed (m/s)', fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            time_series_path = PROC_PATH / \"currents_time_series.png\"\n",
    "            plt.savefig(time_series_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Saved time series plot to: {time_series_path}\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"\\nNote: Install matplotlib for visualizations: pip install matplotlib\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nWARNING: No valid current data found in any files!\")\n",
    "        print(\"Possible issues:\")\n",
    "        print(\"1. River coordinates may be incorrect\")\n",
    "        print(\"2. HYCOM data may have different coordinate system\")\n",
    "        print(\"3. Rivers may be on land where ocean currents aren't defined\")\n",
    "        \n",
    "        # Still save the empty results for debugging\n",
    "        debug_path = PROC_PATH / \"river_currents_debug.csv\"\n",
    "        combined_results.to_csv(debug_path, index=False)\n",
    "        print(f\"\\nSaved debug data to: {debug_path}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nERROR: No results were generated!\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
